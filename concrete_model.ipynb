{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concrete Strength Estimator Regression model using Keras  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I have built a regression model using the deep learning Keras library, and then I experimented that with increasing the number of training epochs and changing number of hidden layers and I made observations of how changing these parameters impacted the performance of the model.\n",
    "A regression model using the Keras library to model the concrete compressive strength data.\n",
    "\n",
    "Project is divided in 4 sections (A, B, C, D as mentioned below).\n",
    "\n",
    "Model is trained with 70% data and tested by 30% of data.\n",
    "\n",
    "For Section A, B and C: 1 hidden layer and 10 nodes each layer Neural Network is used.\n",
    "\n",
    "For Section D: 3 hidden layer and 10 nodes each layer Neural Network is used.\n",
    " \n",
    "The predictors in the data of concrete strength include:\n",
    "1.\tCement\n",
    "2.\tBlast Furnace Slag\n",
    "3.\tFly Ash\n",
    "4.\tWater\n",
    "5.\tSuperplasticizer\n",
    "6.\tCoarse Aggregate\n",
    "7.\tFine Aggregate\n",
    "\n",
    "The target in the data is 'Strength'.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import statistics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing, splitting and normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2.1 - Import csv file\n",
    "concrete_data = pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0101EN/labs/data/concrete_data.csv')\n",
    "# Step 2.2 - Split\n",
    "concrete_data_columns = concrete_data.columns\n",
    "predictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']]\n",
    "target = concrete_data['Strength']\n",
    "# Step 2.3 - Normalize\n",
    "predictors_norm = (predictors - predictors.mean()) / predictors.std()\n",
    "n_cols = predictors_norm.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network (1 Hidden Layers, 10 Nodes)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model_One():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section A : Train & Test (Non-normalize Data, 30% Test , 50 Epochs, 50 Fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "model_One = regression_model_One()\n",
    "error_list = []\n",
    "for x in range(50):\n",
    "    # Split Data into Test and Train\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size = 0.3)\n",
    "    # Run Neural Network\n",
    "    y = model_One.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "    # Find predictions, get error, add to list\n",
    "    y_pred = model_One.predict(X_test)\n",
    "    errors = mean_squared_error(y_test, y_pred)\n",
    "    error_list.append(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing Error Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of the errors =  132.22\n",
      "Standard Deviation of errors =  120.65\n"
     ]
    }
   ],
   "source": [
    "mean_error_One = statistics.mean(error_list)\n",
    "SD_error_One = statistics.stdev(error_list)\n",
    "print(\"Average of the errors = \", round(mean_error_One, 2))\n",
    "print(\"Standard Deviation of errors = \", round(SD_error_One, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section B : Train & Test (Normalized Data, 30% Test, 50 Epochs, 50 Fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Two = regression_model_One()\n",
    "error_list_Two = []\n",
    "for x in range(50):\n",
    "    # Split Data into Test and Train\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size = 0.3)\n",
    "    # Run Neural Network\n",
    "    y = model_Two.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "    # Find predictions, get error, add to list\n",
    "    y_pred = model_Two.predict(X_test)\n",
    "    errors = mean_squared_error(y_test, y_pred)\n",
    "    error_list_Two.append(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing Error Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of the errors =  59.94\n",
      "Standard Deviation of errors =  37.4\n"
     ]
    }
   ],
   "source": [
    "mean_error_Two = statistics.mean(error_list_Two)\n",
    "SD_error_Two = statistics.stdev(error_list_Two)\n",
    "#print(error_list_Two)\n",
    "print(\"Average of the errors = \", round(mean_error_Two, 2))\n",
    "print(\"Standard Deviation of errors = \", round(SD_error_Two, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section C : Train & Test (Normalized Data, 30% Test, 100 Epochs, 100 Fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Three = regression_model_One()\n",
    "error_list_Three = []\n",
    "for x in range(50):\n",
    "    # Split Data into Test and Train\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size = 0.3)\n",
    "    # Run Neural Network\n",
    "    y = model_Three.fit(X_train, y_train, epochs=100, verbose=0)\n",
    "    # Find predictions, get error, add to list\n",
    "    y_pred = model_Three.predict(X_test)\n",
    "    errors = mean_squared_error(y_test, y_pred)\n",
    "    error_list_Three.append(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing Error Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of the errors =  36.67\n",
      "Standard Deviation of errors =  23.14\n"
     ]
    }
   ],
   "source": [
    "mean_error_Three = statistics.mean(error_list_Three)\n",
    "SD_error_Three = statistics.stdev(error_list_Three)\n",
    "#print(error_list_Three)\n",
    "print(\"Average of the errors = \", round(mean_error_Three, 2))\n",
    "print(\"Standard Deviation of errors = \", round(SD_error_Three, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section D : Neural Network (3 Hidden Layers, 10 Nodes)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model_Two():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Test (Normalized, 30 % Test, 50 Epochs , 50 Fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Four = regression_model_Two()\n",
    "error_list_Four = []\n",
    "for x in range(50):\n",
    "    # Split Data into Test and Train\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size = 0.3)\n",
    "    # Run Neural Network\n",
    "    y = model_Four.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "    # Find predictions, get error, add to list\n",
    "    y_pred = model_Four.predict(X_test)\n",
    "    errors = mean_squared_error(y_test, y_pred)\n",
    "    error_list_Four.append(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing Error Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of the errors =  32.36\n",
      "Standard Deviation of errors =  18.07\n"
     ]
    }
   ],
   "source": [
    "mean_error_Four = statistics.mean(error_list_Four)\n",
    "SD_error_Four = statistics.stdev(error_list_Four)\n",
    "#print(error_list_Four)\n",
    "print(\"Average of the errors = \", round(mean_error_Four, 2))\n",
    "print(\"Standard Deviation of errors = \", round(SD_error_Four, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When the Data was normalized (SECTION B): \n",
      " Average error changed from  132.22  to  59.94 \n",
      " Std Dev changed from  120.65  to  37.4\n",
      "\n",
      "When the Epochs increased to 100 (Section C): \n",
      " Average error changed from  59.94  to  36.67 \n",
      " Std Dev changed from  37.4  to  23.14\n",
      "\n",
      "When the more Hidden Layers were added (Section D): \n",
      " Average error changed from  59.94  to  32.36 \n",
      " Std Dev changed from  37.4  to  18.07\n"
     ]
    }
   ],
   "source": [
    "print(\"When the Data was normalized (SECTION B): \\n Average error changed from \", round(mean_error_One, 2), \" to \", round(mean_error_Two, 2), \"\\n Std Dev changed from \", round(SD_error_One, 2),\" to \", round(SD_error_Two, 2))\n",
    "print(\"\\nWhen the Epochs increased to 100 (Section C): \\n Average error changed from \", round(mean_error_Two, 2), \" to \", round(mean_error_Three, 2), \"\\n Std Dev changed from \", round(SD_error_Two, 2),\" to \", round(SD_error_Three, 2))\n",
    "print(\"\\nWhen the more Hidden Layers were added (Section D): \\n Average error changed from \", round(mean_error_Two, 2), \" to \", round(mean_error_Four, 2), \"\\n Std Dev changed from \", round(SD_error_Two, 2), \" to \", round(SD_error_Four, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
